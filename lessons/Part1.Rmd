---
title: "R Data Wrangling - Part 1"
output: html_notebook
---

# D-Lab: R Data Wrangling - Part 1

üîî Have you attended a D-Lab workshop before? Put your **green flag** up on zoom if you have and your **red flag** up if you haven't. We will use these flags throughout the workshop.

‚ö†Ô∏è Do you have the material downloaded from <https://github.com/dlab-berkeley/R-Data-Wrangling-Pilot>? Is your project directory set to R-Data-Wrangling?

## Learning Objectives

Welcome to Part 1 of R Data Wrangling. Our learning objectives for this two part workshop are:

1.  Learn the `tidyverse` functions for **transforming** your data to be used for visualization and analysis

2.  Identify how an "untidy" dataframe gets in the way of data visualization and analysis

3.  Learn the `tidyverse` functions used to **wrangle** a dataframe into "tidy" form

Always remember the [D-Lab](https://dlab.berkeley.edu/home) moto: It's Okay Not to Know!

Throughout this workshop series, we will use the following icons:

*There are too many icons, do I even use all of them?*

üîî **Question**: A quick question to help you understand what's going on.

ü•ä **Challenge**: Interactive exercise. We'll go through these in the workshop!

‚ö†Ô∏è **Warning**: Heads-up about tricky stuff or common mistakes.

üí° **Tip**: How to do something a bit more efficiently or effectively.

üìù **Poll**: A zoom poll to help you learn.

üé¨ **Demo**: Showing off something more advanced so you know what you can use R for in the future.

ü§ñ **chatGPT**: Helps you use chatGPT to improve your code and understanding.

## Tidyverse

Throughout this workshop we will use the `tidyverse` suite of packages, which contains multiple other packages helpful for data wrangling. If you haven't installed `tidyverse` in the past you can install it with the following code:

```{r}
install.packages("tidyverse")
```

Then everyone should load the package and check it is loaded into the session.

```{r}
library(tidyverse)

# this should display the homepage of the documentation for tidyverse
?tidyverse
```

## Tidy Data

In Part 1, we will learn what "tidy" data is and how we can **transform** tidy data to answer questions about our data.

### ü•ä Challenge 1: Exploring the data

Use the `read.csv()` function to read in our dataframe for part 1 in "../data/part1_data.csv".

Use the functions `head()`, `glimpse()`, and `View()` to explore the data and find out what information it contains. What are the observations/units in the data? What are the variables?

```{r}

# read in data - watch out for relative file paths!
d <- read.csv("..")

# explore the data using head(), glimpse(), View()


```

Our data comes from the American Community Survey (ACS), an annual survey conducted by the Census. The ACS samples every 1 in 100 households and asks questions on people's jobs, income, food security, relationships etc. You can explore the data at IPUMS USA: <https://usa.ipums.org/usa/>.

This dataframe is in "tidy" form. This means that **each row is an observation, each column is a variable, and each cell is a single value.**

![Source: Wickham, Cetinkaya-Rundel and Grolemund. 2023. R for Data Science (2e)](../images/tidy_data.png)

Having your data in tidy form facilitates data **analysis** and **visualization**. For example, we might want to calculate the average income for women by each racial group.

üîî Looking at our dataframe, explain in words (no coding required) what we could do to get this? Write your answer in the chat. Don't hit send yet! We will send all our answers together.

### üé¨ Demo: Transforming tidy data

Calculate the average family income for women by racial group. By the end of Part 1, you will be able to do this!

```{r}

d |>
  # subset to women
  filter(sex == 2) |>
  # split the data into racial groups
  group_by(race) |>
  # calculate the average income by group
  summarize(avg_income = mean(income, na.rm = T)) |>
  # sort by average income in descending order
  arrange(desc(avg_income))

```

*Simplify the text below - put in bullet points the answers to: Why is tidy data good?*

-   *we can answer questinos without changing*

-   *standardized data*

-   *\<one more thing\>*

Having our data in tidy form (one observation per row, one variable per column) means we can answer this question without having to change anything about our data. We can get rid of observations that aren't relevant (filtering). We can identify the variables that we care about (subsetting columns). And we can calculate a statistic for different groups in our population (grouping). All these actions come under data **transforming**.

In addition, having data in tidy form gives a standardized way to read data. When there is a clear expectation of how your data is structured, it makes it easier to share with others and for your future self - helping with both reproducibility and collaboration.

The diagram below shows a typical workflow of starting with data, tidying it, understanding it, and then communicating your findings. In today's workshop we will learn how to **transform** our tidy data. In Part 2, we will move one step backwards and learn how to **tidy** messy data.

![Source: Wickham, Cetinkaya-Rundel and Grolemund. 2023. R for Data Science (2e)](../images/workflow.png)

**üìù Poll RData 1-1:** Which of the described dataframes are in tidy form?

## Tidyverse Grammar

The `tidyverse` package that we installed earlier provides useful functions for transforming tidy data. In this workshop we will cover commonly used functions from the `tidyverse` package - some of which we saw above in the demo. Each of these commands work in a similar way.

-   the first input is a tidy dataframe

-   they output a new dataframe

-   they can be "chained" together with piping - this means that the output of a function becomes the input of the next function

## Subsetting Data

Often times we start with a larger dataframe than we actually need. In the example above we only needed women and the variables `race` and `income`. Subsetting means selecting certain observations (rows) and variables (columns).

### select()

The `select()` function allows us to select a subset of variables from our dataframe. The first argument is a tidy dataframe and the second argument is the names of the variables we want.

üí° You do not need to put quotation marks around the variable names. This is a convenient feature of all `tidyverse` functions.

```{r}

select(d, family_ID, person_num, employment_status, age)

```

This is the same as starting with the tidy dataframe, **piping** it into the `select()` command, and then specifying the columns we want.

```{r}

d |>
  select(family_ID, person_num, employment_status)

```

We can also save our selected variables to a new dataframe using the `<-` operator.

```{r}

d_employment <- d |> 
  select(family_ID, person_num, employment_status)

```

üîî Use the `dim()` function to check the number of rows and columns in `d`. How many rows and columns should be in `d_employment`?

```{r}

dim(d)

dim(d_employment)
```

This diagram illustrates what we just did:

![](../images/select.png)

### ü•ä Challenge 2: Using documentation to improve select()

If you want to select more than a few variables, it can become tedious to write them all out. `tidyverse` uses what it calls `<tidy-select>` language to give shortcuts for selecting multiple variables. We can go to the `select()` documentation to see this.

```{r}
?select
```

Using the documentation for guidance, use different `tidy-select` expressions to select the variables described below. If you prefer viewing the documentation online as opposed to in the Help window, you can go to <https://dplyr.tidyverse.org/reference/select.html>.

```{r}

# (1) select all variables to do with state
d |> select(starts_with(...))

# (2) contains (don't give the function, just prompt it)

# (2) select all variables from race to age
# this one is easier than (1) - move out of the challenge 
# then challenge is focused on putting expressions within select 
d |> select(race:age)

# (3) select all variables that are numbers 
## hint: the top of
# --> 
d |> select(where(...))

```

### filter()

Selecting certain rows, especially those that meet specific conditions, is often necessary to answer questions about our data. To do this, we can use the `filter()` function. Like other `tidyverse()` commands it takes a tidy dataframe as its first argument. Next, we tell it what conditions we want the rows to meet. It returns all rows from our dataframe that meet those conditions.

```{r}
# in the demo at the beginning, we asked what the average income was for women by race
# we first needed to filter our dataframe to only women 

d |> 
  filter(sex == 2)

```

The double equals sign tells R to check for rows where `sex` is the value 2.

We can filter rows based on many different types of logical conditions:

| Symbol | Meaning                  |
|--------|--------------------------|
| \<     | less than                |
| \>     | greater than             |
| ==     | equal to                 |
| \<=    | less than or equal to    |
| \>=    | greater than or equal to |
| !=     | not equal to             |
| %in%   | is in                    |
| is.na  | is NA (missing)          |
| !is.na | is not NA                |

```{r}

# return all people that live on the west coast 
d_westcoast <- d |>
  filter(state %in% c("California", "Oregon", "Washington"))

# return all people who do NOT live on the west coast 
d_not_westcoast <- d |>
  filter(!(state %in% c("California", "Oregon", "Washington")))

# Note: in the second one we negated the logical condition "is in the west coast" with the "!" operator 

```

üîî How can we check if we have got the right rows in each of our new dataframes?

```{r}




```

We can also supply multiple conditions at once separated by:

-   `&`: and - returns rows that are true for **both** statements (can also use a comma `,` instead of `&`)

-   `|`: or - returns rows that are true for **either** statements

üîî In general, which condition, `&` or `|`, will return *more* rows? Why?

```{r}

# select all people who are women AND live on the west coast
d |> 
  filter(sex == 2 & state %in% c("California", "Oregon", "Washington"))

# select all people who are women OR people who live on teh west coast 
d |> 
  filter(sex == 2 | state %in% c("California", "Oregon", "Washington"))


```

### ü•ä Challenge 3: Combining conditional statements in filter()

We want a dataframe containing people who are eligible for social security. Let's say that men are eligible age 60 and women are eligible age 55. However, California recently implemented a new policy that says you're eligible for social security at age 50, regardless of gender.

Use `filter()` with the `&` and `|` to create a dataframe of people eligible for social security based on these conditions:

-   Women aged 55 or over who are not in California *or*

-   Men aged 60 or over who are not in California *or*

-   Anyone aged 50 or over who *is* in California

üí° You can use parenthesis to separate out multiple conditions. There are multiple ways to do this.

```{r}




# ANSWERS - copy into solutions script

# simplest answer 
d_ss_v2 <- d |>
  filter((sex == 1 & age >= 60 & state != "California") |
           (sex == 2 & age >= 55 & state != "California") |
           (age >= 50 & state == "California"))


# shorthand, but less intuitive
d_ss <- d |> 
  filter(state != "California" & (sex == 1 & age >= 60 | sex == 2 & age >= 55) |
           state == "California" & age >= 50)


# check both methods get the same dataframe
all.equal(d_ss, d_ss_v2)

# check if we have the right age range
summary(d_ss$age)

# check age range for california
d_ca <- d_ss |>
  filter(state == "California")
summary(d_ca$age)

# check age range for outside california
d_not_ca <- d_ss |>
  filter(state != "California")
summary(d_not_ca$age)
  

```

*Poll: multiple choice about how we would check that we have the right answer*

## Break Time ‚òï

## Creating New Variables

Creating new variables in your existing dataframe is often necessary for visualization and analysis. For example, we might want to plot income in \$1000s to make it more readable, or group people into age bins.

### mutate()

```{r}

# add a column called income_1000
d |>
  mutate(income_1000 = income/1000)

# mutate can make multiple columns at once
d |>
  mutate(income_1000 = income/1000,
         age_group= cut(age, c(0, 20, 40, 60, 80, 100)))

# to keep the columns, assign them to a dataframe
d_new <- d |>
  mutate(income_1000 = income/1000,
         age_group= cut(age, c(0, 20, 40, 60, 80, 100)))
head(d_new)

```

### factor()

A common `mutate()` is converting categorical variables into factors. Factors are a type of variable (like numeric or string) that are used when variables have a finite number of discrete values. For example, in our data `sex` can be one of two values: 1 or 2.

*if the sex one is too boring, and if the challenge is too long with two, instead use employment status and ignore gender*

```{r}

# see the values of sex
table(d$sex)

```

If we plotted the relationship between age and income by gender, R assumes that gender is a numeric variable that could take on any number. The legend on this plot doesn't make sense.

```{r}

d |> 
  filter(age >= 25) |>
  ggplot() +
  geom_smooth(aes(x = age, y = income, color = sex, group = sex), se = FALSE) +
  theme_bw()
  
```

We can instead convert `sex` to a factor, letting R know that it is a categorical variable with only two values.

```{r}

d_factor <- d |>
  mutate(sex_cat = factor(sex))

# look at the values - looks the same
table(d_factor$sex_cat)

```

Now when we plot `sex`, R know that it can only be one of two values and the legend makes more sense.

```{r}

d_factor |> 
  filter(age >= 25) |>
  ggplot() +
  geom_smooth(aes(x = age, y = income, color = sex_cat, group = sex_cat), se = FALSE) +
  theme_bw()
```

We can make the factor version of `sex` even more useful by adding "labels" to it. The values 1 and 2 are the "levels" of the factor, which means the values that the variable can take on.

```{r}
# see the levels of factor with levels()
levels(d_factor$sex_cat)


```

But the levels are only helpful if we know what they mean. A lot of the time, data is given to you in numbers even if the numbers represent something else. Hopefully the data is accompanied by a codebook where you can look up what the numbers mean. For our data, we can go to the online codebook at IPUMS ACS: <https://usa.ipums.org/usa-action/variables/SEX#codes_section>. Here, we see that 1 means "men" and 2 means "women".

We can use the `factor()` command to store this information as part of our variable.

```{r}

# look up the help function for factor
?factor

# create a factor with labels 
d_factor <- d |>
  mutate(sex_cat = factor(sex, labels = c("men", "women")))

# look at the values for the variable
table(d_factor$sex_cat)

```

Now when we plot `sex`, the factor version of the variable provided R all the information it needs to make a more informative plot.

```{r}

d_factor |> 
  filter(age >= 25) |>
  ggplot() +
  geom_smooth(aes(x = age, y = income, color = sex_cat, group = sex_cat), se = FALSE) +
  theme_bw()


```

### ü•ä Challenge 4: Using factor() within mutate()

Similar to `sex`, both `educ` and `employment_status` are categorical variables that are currently stored as numeric variables. Look up their codes in the ACS codebook (link below) and convert them both to factors.

ü§ñ Additional challenge: one of these should be an "ordered factor" and one of them shouldn't. Use chatGPT or google to understand the difference between "ordered factors" and "not ordered factors".

*LOOK AT THE DIFFERENCE BETWEEN GOOGLE AND CHATGPT (the chatGPT one is a lot better)*

Once you understand the difference, decide which variable should be ordered by considering the codebooks and use the help page (?factor) or chatGPT/Google to convert it into an ordered factor.

*Introduce chatGPT earlier*

Codebook for `educ`: <https://usa.ipums.org/usa-action/variables/EDUC#codes_section>

Codebook for `employment_status`: <https://usa.ipums.org/usa-action/variables/EMPSTAT#codes_section>

```{r}

d_c4 <- d |>
  mutate(...)


```

## Grouped Data

At the start of this we asked, what is the average income for women by each racial group? Answering this involves splitting our data into racial groups, then calculating the mean income for each group, then combining the answers together. This is a common task in data transformation, known as "grouping" or "split-apply-combine". The diagram below illustrates the general steps.

![](../images/split_apply.png)

### group_by()

The first step is to tell R that our dataframe should be grouped by a certain variable (or variables). Doing this doesn't change anything about our dataframe, but it lets R know which variable contains the groups that we will later want to apply a command to. For our question, what is the average income by racial group, the variable that divides our data into groups is `race`.

```{r}

# look at the original dataframe
glimpse(d)

# save the same dataframe but grouped by race
d_group <- d |>
  group_by(race)

glimpse(d_group)

```

üîî Do you notice anything different about `glimpse(d)` and `glimpse(d_group)`?

### summarize()

The purpose of grouping a dataframe is so that we can perform some operation on each of the groups. For example, if we want to count how many people there are in each racial group. Or if we want to estimate the average income in each racial group. To do this, we use the `summarize()` command.

`summarize()` is similar to `mutate()` in that it creates new columns. The difference is that it does not keep the original dataframe. Instead, it returns only the new columns created and only one row per group.

```{r}

# count the number of people in each racial group
d_group |>
  summarize(count = n())

```

üí° `n()` is a function that counts the number of rows with a group. Many functions can be used inside `summarize()` to get group summary statistics - for a useful list, ask chatGPT or google.

Note that we used the dataframe `d_group`. What if we used `summarize()` on the original dataframe?

```{r}

d |>
  summarize(count = n())

```

üîî Why is the output for `summarize()` on the dataframe `d` different to the output of `summarize()` on the dataframe `d_group`?

Like `mutate()`, we can create multiple new variables with summary statistics inside `summarize()`.

```{r}

# return the frequency, the minimum income, maximum income, and mean income by racial group
d |>
  # first group by race (we could also use d_group which is already grouped)
  group_by(race) |>
  summarize(freq = n(),
            min_inc = min(income),
            max_inc = max(income),
            avg_inc = mean(income))

```

### ü•ä Challenge 5: Missing values

The code above returned `NA` for the minimum, maximum, and average values of income by racial group. Can you figure out why?

ü§ñ Once you've figured out why this has happened, copy and paste the code into chatGPT and see how you can fix the problem. Do you understand the solutions it suggests?

```{r}

# fixed code


```

### arrange()

At this point we can group our data by race and calculate various summary statistics. The output of `summarize()` is a new dataframe, which we can also apply functions to. A common need is to re-order our rows to communicate something about the data.

For example, what if we want to see which racial groups have the highest and lowest average income?

```{r}

d |>
  # group by racial group
  group_by(race) |>
  # calculate average income - watch for missing values
  summarize(avg_inc = mean(income, na.rm = T)) |>
  # sort in ascending order
  arrange(avg_inc)

```

To sort in descending order, we use the function `desc()` inside `arrange()`.

```{r}

d |>
  # group by racial group
  group_by(race) |>
  # calculate average income - watch for missing values
  summarize(avg_inc = mean(income, na.rm = T)) |>
  # sort in ascending order
  arrange(desc(avg_inc))

```

### ü•ä Challenge 6: Putting it all together

This challenge to combines the functions we have learned throughout Part 1. Starting with our original tidy data, produce a summary statistics table by state. For each state, limiting to working people (`employment_status`) report the following:

-   average income for working people

-   the age of the youngest worker

-   the age of the oldest worker

-   the share of working people with four years of college or more (`educ`)

Sort your final dataframe by the share of people with 4+ years of college.

Here are the links to the codes for the [employment_status](https://usa.ipums.org/usa-action/variables/EMPSTAT#codes_section) and [educ](https://usa.ipums.org/usa-action/variables/EDUC#codes_section) variables. You can choose whether or not to convert these categorical variables to factors (it is not necessary but is good practice).

*DO SOMETHING EARLIER WITH HISPANIC WHERE WE CALCUALTE THE SHARE SO IT'S POSSIBLE HERE*

ü§ñ You can ask chatGPT for help at anytime. If you do, see how you would explain the code it gives you to all of us.

```{r}

# ANSWERS
d |>
  # remove people who aren't working
  filter(employment_status == 1) |>
  # group by state
  group_by(state) |>
  # calculate summary statistics
  summarize(avg_income = mean(income, na.rm = T),
            youngest_worker = min(age),
            eldest_worker = max(age),
            share_BA = mean(educ >= 10)) |>
  # sort by share 4 years of college
  arrange(share_BA)


```

*Do we want to end with the same question as the demo? A very similar one? Or something that sets up the data for Part 2?* *Want the examples above in the group_by() and summarize() to lead to this challenge*

## Takeaways

1.  **tidy** data means one observation per row, one variable per column, and one value per cell - it is a helpful format to have your data in before doing visualizations or analysis

2.  Even with **tidy** data, you often need to change the data in some way before answering questions (eg. subsetting to specific observations or adding new variables)

3.  The functions `select()`, `filter()`, `mutate()`, `factor()`, `group_by()` and `summarize()` from `tidyverse` help us change the data in order to answer questions about our data

*Need to bring in chatGPT earlier so they know how to use it. Do people need to have accounts already?*

*How can I use chatGPT throughout? Are there conceptual questions that chatGPT can answer? Like why do we want to have tidy data? What makes it hard to have less tidy data?*
