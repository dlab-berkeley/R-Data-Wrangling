---
title: "R Data Wrangling - Part 1"
output: html_notebook
---

# D-Lab: R Data Wrangling - Part 1

üîî Have you attended a D-Lab workshop before? Put your **green flag** up on zoom if you have and your **red flag** up if you haven't. We will use these flags throughout the workshop.

‚ö†Ô∏è Do you have the material downloaded from <https://github.com/dlab-berkeley/R-Data-Wrangling-Pilot>? Is your project directory set to R-Data-Wrangling?

## Learning Objectives

Welcome to Part 1 of R Data Wrangling. Our learning objectives for this two part workshop are:

1.  Learn the `tidyverse` functions for **transforming** your data to be used for visualization and analysis

2.  Identify how an "untidy" dataframe gets in the way of data visualization and analysis

3.  Learn the `tidyverse` functions used to **wrangle** a dataframe into "tidy" form

Always remember the [D-Lab](https://dlab.berkeley.edu/home) moto: It's Okay Not to Know!

Throughout this workshop series, we will use the following icons:

üîî **Question**: A quick question to help you understand what's going on.

ü•ä **Challenge**: Interactive exercise. We'll go through these in the workshop!

‚ö†Ô∏è **Warning**: Heads-up about tricky stuff or common mistakes.

üí° **Tip**: How to do something a bit more efficiently or effectively.

üìù **Poll**: A zoom poll to help you learn.

üé¨ **Demo**: Showing off something more advanced so you know what you can use R for in the future.

## Tidyverse

Throughout this workshop we will use the `tidyverse` suite of packages, which contains multiple other packages helpful for data wrangling. If you haven't installed `tidyverse` in the past you can install it with the following code:

```{r}
install.packages("tidyverse")
```

Then everyone should load the package and check it is loaded into the session.

```{r}
library(tidyverse)

# this should display the homepage of the documentation for tidyverse
?tidyverse
```

# Tidy Data

In Part 1, we will learn what "tidy" data is and how we can **transform** tidy data to answer questions about our data.

## ü•ä Challenge 1: Exploring the data

Use the `readRDS()` function to read in our dataframe for part 1 in "../data/part1_data.csv".

Use the functions `head()`, `glimpse()`, and `View()` to explore the data and find out what information it contains. What are the observations/units in the data? What are the variables?

```{r}

# read in data - watch out for relative file paths!
d <- readRDS("..")

# explore the data using head(), glimpse(), View()


```

Our data comes from the American Community Survey (ACS), an annual survey conducted by the Census. The ACS samples every 1 in 100 households and asks questions on people's jobs, income, food security, relationships etc. You can explore the data at IPUMS USA: <https://usa.ipums.org/usa/>. Social scientists typically refer to data about individual people as "micro" data.

This dataframe is in "tidy" form. This means that **each row is an observation, each column is a variable, and each cell is a single value.**

![Source: Wickham, Cetinkaya-Rundel and Grolemund. 2023. R for Data Science (2e)](../images/tidy_data.png)

Having your data in tidy form facilitates data **analysis** and **visualization**. For example, we might want to calculate the average income for women by education.

**üîî Question:** Looking at our dataframe, explain in words (no coding required) what we could do to get this? Write your answer in the chat. Don't hit send yet! We will send all our answers together.

## üé¨ Demo: Transforming tidy data

What is the average family income for adults by education level? By the end of Part 1, you will be able to do this!

```{r}

d |>
  # subset to people age 18+
  filter(age >= 18) |>
  # split the data into education levels
  group_by(educ) |>
  # calculate the average income by group
  summarize(avg_income = mean(income, na.rm = T)) |>
  # sort by average income in descending order
  arrange(desc(avg_income))

```

Why is it helpful to have tidy data (one observation per row, one variable per column)?

-   Perform common **transformations** that let us answer questions about our data (eg. dropping observations, selecting certain variables, calculating statistics for sub-groups of our data)

-   A standardized structure to the data makes it possible for functions in R to operate on the data

-   Clear expectations for how the data are set up make it easier for collaborators and future-you to understand

The diagram below shows a typical workflow of starting with data, tidying it, understanding it, and then communicating your findings. In today's workshop we will learn how to **transform** our tidy data. In Part 2, we will move one step backwards and learn how to **tidy** messy data.

![Source: Wickham, Cetinkaya-Rundel and Grolemund. 2023. R for Data Science (2e)](../images/workflow.png)

# Tidyverse Grammar

The `tidyverse` package that we installed earlier provides useful functions for transforming tidy data. In this workshop we will cover commonly used functions from the `tidyverse` package - some of which we saw above in the demo. Each of these commands work in a similar way.

-   the first input is a tidy dataframe

-   they output a new dataframe

-   they can be "chained" together with piping - this means that the output of a function becomes the input of the next function

# Subsetting Data

Often times we start with a larger dataframe than we actually need. In the example above we only needed women and the variables `race` and `income`. Subsetting means selecting certain observations (rows) and variables (columns).

## select()

The `select()` function allows us to select a subset of variables from our dataframe. The first argument is a tidy dataframe and the second argument is the names of the variables we want.

**üí° Tip:** You do not need to put quotation marks around the variable names. This is a convenient feature of all `tidyverse` functions.

```{r}

select(d, family_ID, person_num, educ, age)

```

This is the same as starting with the tidy dataframe, **piping** it into the `select()` command, and then specifying the columns we want.

```{r}

d |>
  select(family_ID, person_num, educ, age)

```

We can also save our selected variables to a new dataframe using the `<-` operator.

```{r}

d_educ <- d |> 
  select(family_ID, person_num, educ, age)

```

üìù **Poll R-Data 1-1:** The origial dataframe d has 100000 rows and 13 columns. How many rows and columns should be in `d_educ`?

```{r}

dim(d)

dim(d_educ)
```

This diagram illustrates what we just did:

![](../images/select.png)

## ü•ä Challenge 2: Using documentation to improve select()

If you want to select more than a few variables, it can become tedious to write them all out. `tidyverse` uses what it calls `<tidy-select>` language to give shortcuts for selecting multiple variables. We can go to the `select()` documentation to see this.

```{r}
?select

# for example, we can use : to select all variables from race to age
d |> select(race:age)
```

Using the documentation for guidance, use different `tidy-select` expressions to select the variables described below. If you prefer viewing the documentation online as opposed to in the Help window, you can go to <https://dplyr.tidyverse.org/reference/select.html>.

```{r}

# (1) select all variables to do with state
d |> select(starts_with(...))

# (2) contains an underscore "_"


# (3) select all variables that are numbers 
## hint: the description at the top of ?select says how to do this

```

## filter()

Selecting certain rows, especially those that meet specific conditions, is often necessary to answer questions about our data. To do this, we can use the `filter()` function. Like other `tidyverse()` commands it takes a tidy dataframe as its first argument. Next, we tell it what conditions we want the rows to meet. It returns all rows from our dataframe that meet those conditions.

```{r}
# in the demo at the beginning, we asked what the average income was for adults by educational attainment
# we first needed to filter our dataframe to only people 18+ 

d |> 
  filter(age >= 18)

```

The double equals sign tells R to check for rows where `sex` is the value 2.

We can filter rows based on many different types of logical conditions:

| Symbol | Meaning                  |
|--------|--------------------------|
| \<     | less than                |
| \>     | greater than             |
| ==     | equal to                 |
| \<=    | less than or equal to    |
| \>=    | greater than or equal to |
| !=     | not equal to             |
| %in%   | is in                    |
| is.na  | is NA (missing)          |
| !is.na | is not NA                |

```{r}

# return all people that live on the west coast 
d_westcoast <- d |>
  filter(state %in% c("California", "Oregon", "Washington"))

# return all people who do NOT live on the west coast 
d_not_westcoast <- d |>
  filter(!(state %in% c("California", "Oregon", "Washington")))

# Note: in the second one we negated the logical condition "is in the west coast" with the "!" operator 

```

**üîî Question:** How can we check if we have got the right rows in each of our new dataframes?

```{r}




```

We can also supply multiple conditions at once separated by:

-   `&`: and - returns rows that are true for **both** statements (can also use a comma `,` instead of `&`)

-   `|`: or - returns rows that are true for **either** statements

üìù **Poll R-Data 1-2**: In general, which condition, `&` or `|`, will return *more* rows? Why?

```{r}

# select all people who are adults AND live on the west coast
d |> 
  filter(age >= 18 & state %in% c("California", "Oregon", "Washington"))

# select all people who are adults OR people who live on teh west coast 
d |> 
  filter(age >= 18 | state %in% c("California", "Oregon", "Washington"))


```

## ü•ä Challenge 3: Combining conditional statements in filter()

We want a dataframe containing people who are eligible for social security. Let's say that men are eligible age 60 and women (`sex == 2`) are eligible age 55. However, California recently implemented a new policy that says you're eligible for social security at age 50, regardless of gender.

Use `filter()` with the `&` and `|` to create a dataframe of people eligible for social security based on these conditions:

-   Women aged 55 or over who are not in California *or*

-   Men aged 60 or over who are not in California *or*

-   Anyone aged 50 or over who *is* in California

**üí° Tip:** You can use parenthesis to separate out multiple conditions. There are multiple ways to do this.

```{r}

# YOUR CODE HERE
  

```

**üîî Question:** what are some ways we could check that we have filtered down to the correct observations?

```{r}



```

# Break Time ‚òï

# Creating New Variables

Creating new variables in your existing dataframe is often necessary for visualization and analysis. For example, we might want to plot income in \$1000s to make it more readable, or group people into age bins.

## mutate()

```{r}

# add a column called income_1000
d |>
  mutate(income_1000 = income/1000)

# mutate can make multiple columns at once
d |>
  mutate(income_1000 = income/1000,
         age_group= cut(age, c(0, 20, 40, 60, 80, 100)))

# to keep the columns, assign them to a dataframe
d_new <- d |>
  mutate(income_1000 = income/1000,
         age_group= cut(age, c(0, 20, 40, 60, 80, 100)))
head(d_new)

```

## factor()

A common `mutate()` is converting categorical variables into factors. Factors are a type of variable (like numeric or string) that are used when variables have a finite number of discrete values. For example, in our data `worker_type` can be one of three values: 1, 2 or 3. The codes mean:

-   1 = not in the labor force

-   2 = essential worker

-   3 = non-essential worker

```{r}

# see the values of worker_type
table(d$worker_type)

```

If we plotted the relationship between age and income by worker type, R assumes that worker type is a numeric variable that could take on any number. The legend on this plot doesn't make sense.

```{r}

d |> 
  filter(age >= 25) |>
  ggplot() +
  geom_smooth(aes(x = age, y = income, color = worker_type, group = worker_type), se = FALSE) +
  theme_bw()
  
```

We can instead convert `worker_type` to a factor, letting R know that it is a categorical variable with only three values.

```{r}

d_factor <- d |>
  mutate(worker_cat = factor(worker_type))

# look at the values - looks the same
table(d_factor$worker_cat)

```

Now when we plot `worker_cat`, R know that it can only be one of three values and the legend makes more sense.

```{r}

d_factor |> 
  filter(age >= 25) |>
  ggplot() +
  geom_smooth(aes(x = age, y = income, color = worker_cat, group = worker_cat), se = FALSE) +
  theme_bw()
```

We can make the factor version of `worker_type` even more useful by adding "labels" to it. The values 1, 2 and 3 are the "levels" of the factor, which means the values that the variable can take on.

```{r}
# see the levels of factor with levels()
levels(d_factor$worker_cat)

```

But the levels are only helpful if we know what they mean. A lot of the time, data is given to you in numbers even if the numbers represent something else. Hopefully the data is accompanied by a codebook where you can look up what the numbers mean. We know the following:

-   1 = not in the labor force

-   2 = essential worker

-   3 = non-essential worker

We can use the `factor()` command to store this information as part of our variable.

```{r}

# look up the help function for factor
?factor

# create a factor with labels 
d_factor <- d |>
  mutate(worker_cat = factor(worker_type, labels = c("not in LF", "essential", "non-essential")))

# look at the values for the variable
table(d_factor$worker_cat)

```

Now when we plot `worker_cat`, the factor version of the variable provides R all the information it needs to make a more informative plot.

```{r}

d_factor |> 
  filter(age >= 25) |>
  ggplot() +
  geom_smooth(aes(x = age, y = income, color = worker_cat, group = worker_cat), se = FALSE) +
  theme_bw()


```

## ü•ä Challenge 4: Using factor() within mutate()

Similar to `worker_type`, both `sex` and `employment_status` are categorical variables that are currently stored as numeric variables. Look up their codes in the ACS codebook (links below) and convert them both to factors.

Codebook for `sex`: <https://usa.ipums.org/usa-action/variables/SEX#codes_section>

Codebook for `employment_status`: <https://usa.ipums.org/usa-action/variables/EMPSTAT#codes_section>

```{r}

d_ch4 <- d |>
  mutate(...)


```

# Grouped Data

At the start of this we asked, what is the average income for adults by education? Answering this involves splitting our data into education groups, then calculating the mean income for each group, then combining the answers together. This is a common task in data transformation, known as "grouping" or "split-apply-combine". The diagram below illustrates the general steps.

![](../images/split_apply.png)

## group_by()

The first step is to tell R that our dataframe should be grouped by a certain variable (or variables). Doing this doesn't change anything about our dataframe, but it lets R know which variable contains the groups that we will later want to apply a command to. For our question, what is the average income by education, the variable that divides our data into groups is `educ`.

```{r}

# look at the original dataframe
glimpse(d)

# save the same dataframe but grouped by race
d_group <- d |>
  group_by(educ)

glimpse(d_group)

```

**üîî Question:** Do you notice anything different about `glimpse(d)` and `glimpse(d_group)`?

## summarize()

The purpose of grouping a dataframe is so that we can perform some operation on each of the groups. For example, if we want to count how many people there are in each education group. Or if we want to estimate the average income in each education group. To do this, we use the `summarize()` command.

`summarize()` is similar to `mutate()` in that it creates new columns. The difference is that it does not keep the original dataframe. Instead, it returns only the new columns created and only one row per group.

```{r}

# count the number of people in each racial group
d_group |>
  summarize(count = n())

```

**üí° Tip:** `n()` is a function that counts the number of rows with a group. Many functions can be used inside `summarize()` to get group summary statistics - for a useful list, ask chatGPT or google.

Note that we used the dataframe `d_group`. What if we used `summarize()` on the original dataframe?

```{r}

d |>
  summarize(count = n())

```

üìù **Poll R-Data 1-3:** Why is the output for `summarize()` on the dataframe `d` different to the output of `summarize()` on the dataframe `d_group`?

Like `mutate()`, we can create multiple new variables with summary statistics inside `summarize()`.

```{r}

# return the frequency, the minimum income, maximum income, and mean income by racial group
d |>
  # first group by education (we could also use d_group which is already grouped)
  group_by(educ) |>
  summarize(freq = n(),
            min_inc = min(income),
            max_inc = max(income),
            avg_inc = mean(income))

```

## ü•ä Challenge 5: Missing values

The code above returned `NA` for the minimum, maximum, and average values of income by education. Can you figure out why?

Once you've figured out why this has happened, try to fix it. You can do so by looking at the help page for the functions (`?mean`, `?min`, `?max`), or use Google or ChatGPT.

**üí° Tip:** Use Google and/or chatGPT to solve coding problems are a frequent and necessary part of writing code.

```{r}
# YOUR CORRECTED CODE HERE


```

## arrange()

At this point we can group our data by a given variable and calculate various summary statistics. The output of `summarize()` is a new dataframe, which we can also apply functions to. A common need is to re-order our rows to communicate something about the data.

For example, what if we want to which type of worker (`worker_type`) has the highest share of people with college degrees?

```{r}

d |>
  # group by type of worker
  group_by(worker_type) |>
  # calculate the share of people with BAs or graduate degrees - this involves a conditional inside mutate
  summarize(college = mean(educ == "BA" | educ == "graduate")) |>
  # sort in ascending order
  arrange(college)

```

To sort in descending order, we use the function `desc()` inside `arrange()`.

```{r}

d |>
  # group by type of worker
  group_by(worker_type) |>
  # calculate the share of people with BAs or graduate degrees 
  summarize(college = mean(educ == "BA" | educ == "graduate")) |>
  # sort in ascending order
  arrange(desc(college))

```

## ü•ä Challenge 6: Putting it all together

This challenge to combines the functions we have learned throughout Part 1. Starting with our original tidy data, produce a summary statistics table by state for working adults. Starting with `d`, limit to adults (`age`) and those who are working (`empployment_status`). For each state calculate:

-   average income (`income`) - look out for missing values

-   the share of people with a college degree or higher (`educ`)

-   the share of people who are essential workers (`worker_type`) - look out for the variable codes

Sort your final dataframe by the share of people who are essential workers. How many rows should you have?

**ü§ñ chatGPT:** You can ask google or chatGPT for help at anytime. If you do, think how you would explain the code it gives you to all of us.

```{r}

# YOUR CODE HERE


```

# Takeaways

1.  **tidy** data means one observation per row, one variable per column, and one value per cell - it is a helpful format to have your data in before doing visualizations or analysis

2.  Even with **tidy** data, you often need to change the data in some way before answering questions (eg. subsetting to specific observations or adding new variables)

3.  The functions `select()`, `filter()`, `mutate()`, `factor()`, `group_by()` and `summarize()` from `tidyverse` help us change the data in order to answer questions about our data

## Next steps...

Transforming data using functions from `tidyverse` are often necessary before performing statistical analyses, such as training machine learning models. You're now prepared to take DLab's [R Machine Learning](https://github.com/dlab-berkeley/r-machine-learning-pilot) to learn how to do machine learning using `tidymodels`.
